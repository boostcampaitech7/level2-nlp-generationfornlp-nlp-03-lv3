{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error connecting to PostgreSQL database: connection to server at \"localhost\" (::1), port 30665 failed: received invalid response to SSL negotiation: H\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "db_host = 'localhost'\n",
    "db_name = 'mlflow_db'\n",
    "db_user = 'mlflow_user'\n",
    "db_password = '83forever'\n",
    "db_port=30665\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=db_name,\n",
    "        user=db_user,\n",
    "        password=db_password,\n",
    "        host=db_host,\n",
    "        port=db_port,\n",
    "    )\n",
    "    print('PostgreSQL 데이터베이스에 연결되었습니다.')\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(f'Error connecting to PostgreSQL database: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:30665\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실험 데이터 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Name: Gen_NLP_exp, Experiment ID: 1\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# 모든 실험 조회\n",
    "experiments = client.search_experiments()\n",
    "for exp in experiments:\n",
    "    print(f\"Experiment Name: {exp.name}, Experiment ID: {exp.experiment_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: 72eec8c6064a43738e3f36c8c349256f, Metrics: {'train_runtime': 39.785, 'train_samples_per_second': 1.257, 'train_steps_per_second': 1.257, 'total_flos': 1289389569377280.0, 'train_loss': 3.341466369628906, 'epoch': 5.0, 'eval_accuracy': 0.4, 'eval_loss': 4.805677890777588, 'eval_runtime': 3.3221, 'eval_samples_per_second': 1.505, 'eval_steps_per_second': 1.505}, Params: {'peft_type': 'PeftType.LORA', 'auto_mapping': 'None', 'base_model_name_or_path': 'beomi/Qwen2.5-7B-Instruct-kowiki-qa-context', 'revision': 'None', 'task_type': 'CAUSAL_LM', 'inference_mode': 'False', 'r': '6', 'target_modules': \"{'k_proj', 'q_proj'}\", 'lora_alpha': '8', 'lora_dropout': '0.1', 'fan_in_fan_out': 'False', 'bias': 'none', 'use_rslora': 'False', 'modules_to_save': 'None', 'init_lora_weights': 'True', 'layers_to_transform': 'None', 'layers_pattern': 'None', 'rank_pattern': '{}', 'alpha_pattern': '{}', 'megatron_config': 'None', 'megatron_core': 'megatron.core', 'loftq_config': '{}', 'use_dora': 'False', 'layer_replication': 'None', 'warmup_steps': '0', 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': 'True', 'logging_dir': './resources/checkpoint/runs/Nov18_13-58-07_instance-13765', 'logging_strategy': 'steps', 'logging_first_step': 'False', 'logging_steps': '200', 'logging_nan_inf_filter': 'True', 'save_strategy': 'epoch', 'save_steps': '500', 'save_total_limit': '2', 'save_safetensors': 'True', 'save_on_each_node': 'False', 'save_only_model': 'False', 'restore_callback_states_from_checkpoint': 'False', 'no_cuda': 'False', 'use_cpu': 'False', 'use_mps_device': 'False', 'seed': '42', 'data_seed': 'None', 'jit_mode_eval': 'False', 'use_ipex': 'False', 'bf16': 'False', 'fp16': 'False', 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': 'False', 'fp16_full_eval': 'False', 'tf32': 'None', 'local_rank': '0', 'ddp_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': 'False', 'debug': '[]', 'dataloader_drop_last': 'False', 'eval_steps': 'None', 'dataloader_num_workers': '0', 'dataloader_prefetch_factor': 'None', 'past_index': '-1', 'run_name': 'Gen_NLP-2024-11-18-13-58-1731905886', 'disable_tqdm': 'False', 'remove_unused_columns': 'True', 'label_names': 'None', 'load_best_model_at_end': 'True', 'metric_for_best_model': 'accuracy', 'greater_is_better': 'True', 'ignore_data_skip': 'False', 'fsdp': '[]', 'fsdp_min_num_params': '0', 'fsdp_config': \"{'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}\", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'accelerator_config': \"{'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}\", 'deepspeed': 'None', 'label_smoothing_factor': '0.0', 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': 'False', 'group_by_length': 'False', 'length_column_name': 'length', 'report_to': \"['mlflow']\", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'ddp_broadcast_buffers': 'None', 'dataloader_pin_memory': 'True', 'dataloader_persistent_workers': 'False', 'skip_memory_metrics': 'True', 'use_legacy_prediction_loop': 'False', 'push_to_hub': 'False', 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': 'False', 'hub_always_push': 'False', 'gradient_checkpointing': 'False', 'gradient_checkpointing_kwargs': 'None', 'include_inputs_for_metrics': 'False', 'include_for_metrics': '[]', 'eval_do_concat_batches': 'True', 'fp16_backend': 'auto', 'evaluation_strategy': 'None', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': 'False', 'full_determinism': 'False', 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': '1800', 'torch_compile': 'False', 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'dispatch_batches': 'None', 'split_batches': 'None', 'include_tokens_per_second': 'False', 'include_num_input_tokens_seen': 'False', 'neftune_noise_alpha': 'None', 'optim_target_modules': 'None', 'vocab_size': '152064', 'max_position_embeddings': '32768', 'hidden_size': '3584', 'intermediate_size': '18944', 'num_hidden_layers': '28', 'num_attention_heads': '28', 'use_sliding_window': 'False', 'sliding_window': 'None', 'max_window_layers': '28', 'num_key_value_heads': '4', 'hidden_act': 'silu', 'initializer_range': '0.02', 'rms_norm_eps': '1e-06', 'use_cache': 'False', 'rope_theta': '1000000.0', 'rope_scaling': 'None', 'attention_dropout': '0.0', 'return_dict': 'True', 'output_hidden_states': 'False', 'output_attentions': 'False', 'torchscript': 'False', 'torch_dtype': 'float16', 'use_bfloat16': 'False', 'tf_legacy_loss': 'False', 'pruned_heads': '{}', 'tie_word_embeddings': 'False', 'chunk_size_feed_forward': '0', 'is_encoder_decoder': 'False', 'is_decoder': 'False', 'cross_attention_hidden_size': 'None', 'add_cross_attention': 'False', 'tie_encoder_decoder': 'False', 'max_length': '20', 'min_length': '0', 'do_sample': 'False', 'early_stopping': 'False', 'num_beams': '1', 'num_beam_groups': '1', 'diversity_penalty': '0.0', 'temperature': '1.0', 'top_k': '50', 'top_p': '1.0', 'typical_p': '1.0', 'repetition_penalty': '1.0', 'length_penalty': '1.0', 'no_repeat_ngram_size': '0', 'encoder_no_repeat_ngram_size': '0', 'bad_words_ids': 'None', 'num_return_sequences': '1', 'output_scores': 'False', 'return_dict_in_generate': 'False', 'forced_bos_token_id': 'None', 'forced_eos_token_id': 'None', 'remove_invalid_values': 'False', 'exponential_decay_length_penalty': 'None', 'suppress_tokens': 'None', 'begin_suppress_tokens': 'None', 'architectures': \"['Qwen2ForCausalLM']\", 'finetuning_task': 'None', 'id2label': \"{0: 'LABEL_0', 1: 'LABEL_1'}\", 'label2id': \"{'LABEL_0': 0, 'LABEL_1': 1}\", 'tokenizer_class': 'None', 'prefix': 'None', 'bos_token_id': '151643', 'pad_token_id': 'None', 'eos_token_id': '151645', 'sep_token_id': 'None', 'decoder_start_token_id': 'None', 'task_specific_params': 'None', 'problem_type': 'None', '_name_or_path': 'beomi/Qwen2.5-7B-Instruct-kowiki-qa-context', '_attn_implementation_autoset': 'True', 'transformers_version': '4.46.2', 'model_type': 'qwen2', 'output_dir': './resources/checkpoint/beomi/Qwen2.5-7B-Instruct-kowiki-qa-context', 'overwrite_output_dir': 'False', 'do_train': 'True', 'do_eval': 'True', 'do_predict': 'False', 'eval_strategy': 'epoch', 'prediction_loss_only': 'False', 'per_device_train_batch_size': '1', 'per_device_eval_batch_size': '1', 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': '1', 'eval_accumulation_steps': 'None', 'eval_delay': '0', 'torch_empty_cache_steps': 'None', 'learning_rate': '2e-05', 'weight_decay': '0.01', 'adam_beta1': '0.9', 'adam_beta2': '0.999', 'adam_epsilon': '1e-08', 'max_grad_norm': '1', 'num_train_epochs': '5', 'max_steps': '-1', 'lr_scheduler_type': 'cosine', 'lr_scheduler_kwargs': '{}', 'warmup_ratio': '0.0', 'batch_eval_metrics': 'False', 'eval_on_start': 'False', 'use_liger_kernel': 'False', 'eval_use_gather_object': 'False', 'average_tokens_across_devices': 'False', 'dataset_text_field': 'text', 'packing': 'False', 'max_seq_length': '2000', 'dataset_num_proc': 'None', 'dataset_batch_size': '1000', 'model_init_kwargs': 'None', 'dataset_kwargs': '{}', 'eval_packing': 'None', 'num_of_sequences': '1024', 'chars_per_token': '<CHARS_PER_TOKEN>', 'use_liger': 'False'}\n"
     ]
    }
   ],
   "source": [
    "# 특정 실험의 실행 조회\n",
    "runs = client.search_runs(experiment_ids=[exp.experiment_id])\n",
    "for run in runs:\n",
    "    print(f\"Run ID: {run.info.run_id}, Metrics: {run.data.metrics}, Params: {run.data.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 로그 데이터 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: Gen_NLP_exp, Version: 2, Stage: None\n"
     ]
    }
   ],
   "source": [
    "# 모델 로드\n",
    "model_name = 'Gen_NLP_exp'\n",
    "model_version = 2\n",
    "\n",
    "# 모델 메타데이터 조회\n",
    "model_info = client.get_model_version(name=model_name, version=model_version)\n",
    "print(f\"Model Name: {model_info.name}, Version: {model_info.version}, Stage: {model_info.current_stage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 artifact 다운로드\n",
    "-> 실험 로그 파일 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.store.artifact.models_artifact_repo import ModelsArtifactRepository\n",
    "\n",
    "# 아티팩트 다운로드\n",
    "model_name = 'Gen_NLP_exp1'\n",
    "model_version = 1\n",
    "model_uri = client.get_model_version_download_uri(model_name, model_version)\n",
    "ModelsArtifactRepository(model_uri).download_artifacts(artifact_path=\"저장할 로컬 path\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_sh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
